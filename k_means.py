# -*- coding: utf-8 -*-
"""K-Means.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/16pgyo4AVS-7lFmUFnJ-CVv6If3o-gMJh
"""

#import os
#os.chdir('/content/drive/My Drive/Code/Ass2Data')

import numpy as np
import pandas as pd
import copy 
import math
import csv
import time
import operator
import matplotlib
import matplotlib.pyplot as plt

# Default value
SSE = 0
	
def initClusters(k):
	clusters = []
	for i in range(k):
			newList = []
			clusters.append(newList)
	return clusters

def findClosestCentroid(centroids,data_vector):
		#global SSE
		min = 100000000000
		minDistCentIndex = 0
		for ci in centroids:
			distance = sum([(a-b) ** 2 for a,b in zip(centroids[ci], data_vector)])
			if distance < min:
					min = distance
					minDistCentIndex = ci
		#SSE += min
		return minDistCentIndex

def findSample(df,index):
	lst = df.loc[index]
	lst = lst.to_numpy().tolist()
	lst = lst[:len(lst)-1]
	return lst

def calSSE(centroid,sample):
	global SSE
	#print(centroid)
	SSE += sum([(a-b) ** 2 for a,b in zip(centroid, sample)])

def updateCentroid(df,clusters,centroids):
	diff = 0
	clusterIndex = 0
	for cluster in clusters:
		if clusterIndex == 0 or len(cluster) == 0:
			clusterIndex += 1
			continue

		#print(cluster)
		newCentroid = [0]*(len(df.columns)-1)
		for dataIndex in cluster:
			lst = findSample(df,dataIndex)
			newCentroid = [(a+b) for a,b in zip(lst, newCentroid)]
		newCentroid[:] = [x / len(cluster) for x in newCentroid]
		diff += math.sqrt(sum([(a-b) ** 2 for a,b in zip(centroids[clusterIndex], newCentroid)]))
		centroids[clusterIndex] = newCentroid
		clusterIndex += 1
		
	return diff

def findCategories(df,clusters,labels):
	confMatrix = np.zeros((len(clusters),len(labels)))
	row = 0
	mis_classifications = 0
	for cluster in clusters:
		for item in cluster:
			label = df.at[item,'label']
			confMatrix[row][labels[label]] += 1
		#maxpos = np.where(lst == np.amax(lst))
		index, value = max(enumerate(confMatrix[row]), key=operator.itemgetter(1))
		mis_classifications += sum(confMatrix[row]) - value
		row += 1
	return mis_classifications

def KMeans(df,k,epsilon):
	global SSE
	t = 0
	finalClusters = []
	#high = df.max(numeric_only=True).max()
	#low = df.min(numeric_only=True).min()
	randomPoints = np.random.randint(0,len(df),k)

	centroids = {
			i : findSample(df,randomPoints[i]) #np.random.uniform(low, high, len(df.columns)-1)
			for i in range(k)
	}
	print(centroids)
	while True:
		t = t+1
		clusters	= initClusters(k)
		
		for index in range(len(df)):
			data_vector = findSample(df,index)
			closestCent = findClosestCentroid(centroids,data_vector)
			calSSE(centroids[closestCent],data_vector)
			clusters[closestCent].append(index)
		
		diff = updateCentroid(df,clusters,centroids)
		if diff <= epsilon:
			finalClusters = clusters
			#print(clusters)
			break
		SSE = 0

	return finalClusters

def plotRelation(x,y,label):
	plt.figure(figsize=(8, 6),dpi=100)
	plt.xlabel('K')
	plt.ylabel(label)
	plt.plot(x,y,label = 'K-Mean')
	plt.legend()

def fetchData(filename):
 df = pd.read_csv(filename)
 return df
 
 
def Main():
	df = fetchData('Spiral.txt')
	#print(df)
	features = df.label.unique()
	i = 0
	labels = {}
	for item in features:
		labels[item] = i
		i += 1
	print(labels)
	print(df.describe())

	listk = []
	listSSE = []
	mis_classifications = []
	times = []
	for k in range(1,10):
		start_time = time.time()
		clusters = KMeans(df,k,0.001)
		mis_classifications.append(findCategories(df,clusters,labels))
		listk.append(k)
		listSSE.append(SSE)
		end_time = time.time()
		times.append(end_time-start_time)

	d = { 
			 'Clusters': listk,
			 'SSE': listSSE,
			 'Misclassification': mis_classifications,
			 'RunTime':times,
			 }
	df2 = pd.DataFrame(data = d)

	print(df2)

	df2.to_csv ('Kmeans_result6_Spiral.csv', index = False, header=True)
	plotRelation(listk[:5],mis_classifications[:5],'MisClassification')
	plotRelation(listk,listSSE,'SSE')
	
if __name__ == "__main__":
    Main()

