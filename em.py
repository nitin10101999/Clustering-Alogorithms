# -*- coding: utf-8 -*-
"""EM.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/1mwahDm-m4Yoy-nEZq1ko-Gdz2V9l8Pd6
"""

#import os
#os.chdir('/content/drive/My Drive/Code/Ass2Data')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.stats import multivariate_normal
import copy 
import math
import csv
import time
import matplotlib.pyplot as plt
#import seaborn as sns
#sns.set_theme(style="darkgrid")
	
# Default value
SSE = 0 
phi = -1
pi = 3.141593
df = None

def findSample(index):
	lst = df.loc[index]
	lst = lst.to_numpy().tolist()
	lst = lst[:len(lst)-1]
	return lst

def calgaussDist(x,u,covMat,d):
	x_minus_u = np.subtract(x,u)
	x_minus_u = np.matrix(x_minus_u);
	x_minus_u_T =	x_minus_u.transpose()
	covMatInv = np.linalg.inv(covMat)
	dist = 1/((pow(2*pi,d/2))*(pow(np.linalg.det(covMat),1/2)))
	dist = dist * math.exp(-((x_minus_u.dot(covMatInv)).dot(x_minus_u_T))/2)
	return dist

def CalPosteriorProb(k,centroids,covMatrices,P_Ci_s):
	n = len(df)
	d = len(df.columns) - 1
	w = np.zeros((k,n))
	f = np.zeros((n,k))
	for i in range(n):
		xi = findSample(i)
		for j in range(k):
			f[i][j] = multivariate_normal.pdf(xi,centroids[j],covMatrices[j]) #calgaussDist(xi,centroids[j],covMatrices[j],d) 
	
	for i in range(k):
		for j in range(n):
			num = f[j][i] * P_Ci_s[i]
			denom = 0.0
			for a in range(k):
				denom += f[j][a] * P_Ci_s[a]	
			w[i][j] = num/float(denom)
	return w

def calMean(w,i):
	n = len(df)
	d = len(df.columns)-1
	num = [0]*d
	denom = sum(w[i])
	for j in range(n):
		xj = findSample(j)
		xj = np.multiply(xj,w[i][j])
		num = np.add(xj,num)
	mean = np.divide(num,denom)
	return mean

def calCovVariance(w,i,ui,k):
	n = len(df)
	d = len(df.columns)-1
	newCov = np.zeros((d,d))
	#denom = 0.0
	for j in range(n):
		xj = findSample(j)
		xj_minus_ui = np.subtract(xj,ui)
		xj_minus_ui = np.matrix(xj_minus_ui)
		xj_minus_ui_T = xj_minus_ui.transpose()
		temp = xj_minus_ui_T.dot(xj_minus_ui)
		temp = np.array(temp)
		temp = np.multiply(temp,w[i][j])
		newCov = np.add(newCov,temp)
		#denom += w[i][j]
	newCov = np.divide(newCov,sum(w[i]))
	return newCov

def calP_Ci(w,i):
	n = len(df)
	newP_Ci = sum(w[i])
	newP_Ci = newP_Ci/float(n)
	return newP_Ci

def EM(k,epsilon):
	t = 0
	randomPoints = np.random.randint(0,len(df),k)

	centroids = [
			findSample(randomPoints[i]) 
			for i in range(k)
	]
	covMatrices = [
			np.identity(len(df.columns)-1)
			for i in range(k)
	]
	P_Ci_s = [
			1/float(k)
			for i in range(k)
	]
	PosteriorProbs = []
	while True:
		t = t + 1
		# Expectation Step
		PosteriorProbs = CalPosteriorProb(k,centroids,covMatrices,P_Ci_s)

		dist = 0.0
		# Maximization Step
		for i in range(k):
			# re-estimate mean
			old_ui = centroids[i]
			centroids[i] = calMean(PosteriorProbs,i)
			dist += math.sqrt(sum([pow(a-b, 2) for a,b in zip(old_ui, centroids[i])]))

			# re-estimate CovVariance
			covMatrices[i] = calCovVariance(PosteriorProbs,i,old_ui,k) # Confuse
			# re-estimate priors
			P_Ci_s[i] = calP_Ci(PosteriorProbs,i)
		
		if dist <= epsilon:
			break
		print(P_Ci_s)
	
	return centroids,covMatrices,P_Ci_s

def fetchData(filename):
	global df
	df = pd.read_csv(filename)
	if filename == 'iris.data':
		cols = np.array(df.columns)
		features = cols[:len(df.columns)-1]
		category = cols[len(df.columns)-1:]
		x = df.loc[:,features].values
		y = df.loc[:,category].values
		#x = StandardScaler().fit_transform(x)
		pca = PCA(n_components=2)
		pc = pca.fit_transform(x)
		pdf = pd.DataFrame(data = pc, columns=['x1','x2'])
		df = pd.concat([pdf,df[['label']]],axis=1)

	return df

def Plot(centroids,covMatrices,P_Ci_s,K):
	high = df.max(numeric_only=True)
	low = df.min(numeric_only=True)
	lenght = 250
	x1_max = high.x1
	x2_max = high.x2
	x1_min = low.x1
	x2_min = low.x2
	x1_diff = (x1_max - x1_min)/lenght
	x2_diff = (x2_max - x2_min)/lenght
	x1 = []
	x2 = []
	for i in range(lenght):
		x1.append(x1_min + i * x1_diff)
		x2.append(x2_min + i * x2_diff)
	X,Y = np.meshgrid(np.array(x1),np.array(x2))

	ProbDensities = []
	X1 = []
	Y1 = []
	for i in range(lenght):
		for j in range(lenght):
			x = [X[i][j],Y[i][j]] 
			X1.append(X[i][j])
			Y1.append(Y[i][j])
			total = 0
			for k in range(3):
				dist = multivariate_normal.pdf(x,centroids[k],covMatrices[k])
				total +=	dist * P_Ci_s[k]
			ProbDensities.append(total)
	
	fig = plt.figure(figsize=(10, 8))
	ax = plt.gca(projection='3d')

	ax.plot_trisurf(X1, Y1, ProbDensities,
									cmap='viridis',linewidth=0, alpha=0.7, antialiased=True, zorder = 0.5);
	ax.scatter(df['x1'],df['x2'],s = 40)
	ax.set_title(K)
	ax.set_xlabel('x1')
	ax.set_ylabel('x2')
	ax.set_zlabel('PC')

def Main():
	fetchData('iris.data')
	k = 3
	centroids,covMatrices,P_Ci_s = EM(k,0.001)
	
	# if want to Plot then Uncomment below code
	"""Plot(df,centroids,covMatrices,P_Ci_s,'K = '+str(k))

	sns.displot(df, x="x1", hue="label", kind="kde", fill=True)
	sns.displot(df, x="x2", hue="label", kind="kde", fill=True)

	sns.relplot(x="x1", y="x2", hue="label", data=df,aspect=1);

	sns.set(rc={'figure.figsize':(11.7,8.27)})
	sns.kdeplot(
			data=df, x="x1", y="x2", hue="label", fill=True,
	)"""
	
if __name__ == "__main__":
    Main()

