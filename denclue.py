# -*- coding: utf-8 -*-
"""Denclue.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/1tvN5pS4dgSa6YNla0yNm58dnMneARArv
"""

#import os
#os.chdir('/content/drive/My Drive/Code/Ass2Data')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import copy 
import math
import csv
import time
import matplotlib.pyplot as plt
#import seaborn as sns
#sns.set_theme(style="darkgrid")

# Default value
SSE = 0 
phi = -1
pi = 3.141593
df = None

def findSample(index):
	lst = df.loc[index]
	lst = lst.to_numpy().tolist()
	lst = lst[:len(lst)-1]
	return lst

def cal_kernel(x,xi_index,h):
	xi = findSample(xi_index)
	Kernel = (1/((2*pi)**(len(x)/2)))*math.exp(-((sum([(a-b) ** 2 for a,b in zip(x, xi)]))/(float(2*h*h))))
	return Kernel
	
def cal_xt_plus_1(xt,h):
	xt_plus_1 = [0]*len(xt)
	denominator = 0
	for xi_index in range(len(df)):
		kernel = cal_kernel(xt,xi_index,h)
		templst = np.multiply(xt,kernel) #[i * kernel for i in xt]
		xt_plus_1 = np.add(xt_plus_1,templst) #[(a+b) for a,b in zip(xt_plus_1, templst)]
		denominator += kernel
	xt_plus_1 = np.divide(xt_plus_1,denominator) #[i / denominator for i in xt_plus_1]
	return xt_plus_1

def FindAttractor(x_index,h,epsilon):
	t = 0
	xt = findSample(x_index)
	while True:
		xt_plus_1 = cal_xt_plus_1(xt,h)
		t += 1
		dist = math.sqrt(sum([(a-b) ** 2 for a,b in zip(xt, xt_plus_1)]))
		if dist <= epsilon:
			break
		xt = xt_plus_1
	return xt

def calDensity(x_attractor,h):
	d = len(x_attractor)
	n = len(df)
	density = (1/float(n*pow(h,d)))
	temp = 0
	for xi_index in range(n):
		temp += cal_kernel(x_attractor,xi_index,h)
	
	density *= temp
	return density

def PointsIn_r_Radius(x,epsilon):
	x_sample = findSample(x)
	pointsIn_r = []
	for xi in range(len(df)):
		xi_sample = findSample(xi)
		dist = math.sqrt(sum([(a-b) ** 2 for a,b in zip(xi_sample, x_sample)]))
		if dist<= epsilon:
			pointsIn_r.append(xi)

	return pointsIn_r

def densityReachable(xi_attractor,xj_attractor,h,epsilon,E): 
	midPoint = [(a+b)/2 for a,b in zip(xi_attractor, xj_attractor)]
	radius = math.sqrt(sum([(a-b) ** 2 for a,b in zip(midPoint, xj_attractor)]))
	isReachable = True
	for xi in range(len(df)):
		xi_sample = findSample(xi)
		dist = math.sqrt(sum([(a-b) ** 2 for a,b in zip(xi_sample, midPoint)]))
		if dist <= radius and calDensity(xi_sample,h) < E:
			isReachable = False
			break

	return isReachable

def DFS(temp,v,visited,Maximal):
	visited[v] = True
	temp.append(v)
	for i in Maximal[v]:
		if visited[i] == False:
			temp = DFS(temp,i,visited,Maximal)
	
	return temp

def findConnectedComponents(Maximal):
	visited = []
	cc = []
	for i in range(len(Maximal)): 
		visited.append(False)
	for v in range(len(Maximal)): 
		if visited[v] == False:
			temp = []
			cc.append(DFS(temp,v,visited,Maximal))
	return cc

def checkAttractor(attractors,x_attractor,epsilon):
	i =0
	for xi in attractors:
		dist = math.sqrt(sum([(a-b) ** 2 for a,b in zip(x_attractor, xi)]))
		if dist <= epsilon:
			return i
		i += 1

	return -1
	
def Denclue(h,E,epsilon):
	attractors = []
	attractorId = 0
	clusters = {}
	f = []
	for x_index in range(len(df)):
		x_attractor = FindAttractor(x_index,h,epsilon)
		index = checkAttractor(attractors,x_attractor,epsilon)
		density = calDensity(x_attractor,h)
		f.append(density)
		#print(density)
		if density >= E:
			if index == -1:
				attractors.append(x_attractor)
				clusters.setdefault(attractorId, []).append(x_index) # add x to their attractor
				attractorId += 1
				#print('1')
			else:
				clusters.setdefault(index, []).append(x_index) # add x to their attractor
				#print('2')
	Maximal = []
	for i in range(0,len(attractors)):
		lst = []
		for j in range(i+1,len(attractors)):
			if densityReachable(attractors[i],attractors[j],h,epsilon,E): 
				lst.append(j)
		Maximal.append(lst)
	
	cc = findConnectedComponents(Maximal)
	mainClusters = []
	for row in cc:
		lst	= []
		for id in row:
			lst.extend(clusters[id])
		mainClusters.append(lst)
	return mainClusters

def fetchData(filename):
	global df
	df = pd.read_csv(filename)
	if filename == 'iris.data':
		cols = np.array(df.columns)
		features = cols[:len(df.columns)-1]
		category = cols[len(df.columns)-1:]
		x = df.loc[:,features].values
		y = df.loc[:,category].values
		#x = StandardScaler().fit_transform(x)
		pca = PCA(n_components=2)
		pc = pca.fit_transform(x)
		pdf = pd.DataFrame(data = pc, columns=['x1','x2'])
		df = pd.concat([pdf,df[['label']]],axis=1)
		


def Plot(h):
	lenght = 100
	high = df.max(numeric_only=True)
	low = df.min(numeric_only=True)
	x1_max = high.x1
	x2_max = high.x2
	x1_min = low.x1
	x2_min = low.x2
	x1_diff = (x1_max - x1_min)/lenght
	x2_diff = (x2_max - x2_min)/lenght
	x1 = []
	x2 = []
	for i in range(lenght):
		x1.append(x1_min + i * x1_diff)
		x2.append(x2_min + i * x2_diff)
	X,Y = np.meshgrid(np.array(x1),np.array(x2))

	ProbDensities = []
	X1 = []
	Y1 = []
	for i in range(lenght):
		for j in range(lenght):
			x = [X[i][j],Y[i][j]] 
			X1.append(X[i][j])
			Y1.append(Y[i][j])
			density = calDensity(x,h)
			ProbDensities.append(density)
	
	fig = plt.figure(figsize=(10, 8))
	ax = plt.gca(projection='3d')

	ax.plot_trisurf(X1, Y1, ProbDensities,
									cmap='viridis',linewidth=0, alpha=0.7, antialiased=True, zorder = 0.5);
	ax.scatter(df['x1'],df['x2'],s = 40)
	ax.set_xlabel('x1')
	ax.set_ylabel('x2')
	ax.set_zlabel('PC')
	
def Main():
	fetchData('iris.data')
	# if want to run Denclue Uncomment below line but be careful it takes too much time to run
	#clusters = Denclue(h = 0.2,E = 0.08,epsilon = 0.3)
	Plot(h=0.2)

if __name__ == "__main__":
    Main()

